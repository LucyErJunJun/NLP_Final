{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP dobj X.X. False False\n",
      "startup startup NOUN NN advcl xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"main.py\", line 32, in <module>\r\n",
      "    from tqdm import tqdm\r\n",
      "ModuleNotFoundError: No module named 'tqdm'\r\n"
     ]
    }
   ],
   "source": [
    " !python3 main.py \\\n",
    "    --use_gpu \\\n",
    "    --model \"baseline\" \\\n",
    "    --model_path \"squad_model.pt\" \\\n",
    "    --train_path \"datasets/squad_train.jsonl.gz\" \\\n",
    "    --dev_path \"datasets/squad_dev.jsonl.gz\" \\\n",
    "    --output_path \"squad_predictions.txt\" \\\n",
    "    --hidden_dim 256 \\\n",
    "    --bidirectional \\\n",
    "    --do_train \\\n",
    "    --do_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for training and evaluating QA models.\n",
    "\n",
    "Example command to train the (medium-sized) baseline model on SQuAD\n",
    "with a GPU, and write its predictions to an output file:\n",
    "\n",
    "Usage:\n",
    "    python3 main.py \\\n",
    "        --use_gpu \\\n",
    "        --model \"baseline\" \\\n",
    "        --model_path \"squad_model.pt\" \\\n",
    "        --train_path \"datasets/squad_train.jsonl.gz\" \\\n",
    "        --dev_path \"datasets/squad_dev.jsonl.gz\" \\\n",
    "        --output_path \"squad_predictions.txt\" \\\n",
    "        --hidden_dim 256 \\\n",
    "        --bidirectional \\\n",
    "        --do_train \\\n",
    "        --do_test\n",
    "\n",
    "Author:\n",
    "    Shrey Desai and Yasumasa Onoe\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import QADataset, Tokenizer, Vocabulary\n",
    "\n",
    "from model import BaselineReader\n",
    "from utils import cuda, search_span_endpoints, unpack\n",
    "\n",
    "\n",
    "_TQDM_BAR_SIZE = 75\n",
    "_TQDM_LEAVE = False\n",
    "_TQDM_UNIT = ' batches'\n",
    "_TQDM_OPTIONS = {\n",
    "    'ncols': _TQDM_BAR_SIZE, 'leave': _TQDM_LEAVE, 'unit': _TQDM_UNIT\n",
    "}\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Training arguments.\n",
    "parser.add_argument('--device', type=int)\n",
    "parser.add_argument(\n",
    "    '--use_gpu',\n",
    "    action='store_true',\n",
    "    help='whether to use GPU',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--model',\n",
    "    type=str,\n",
    "    required=True,\n",
    "    choices=['baseline'],\n",
    "    help='which model to use',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--model_path',\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help='path to load/save model checkpoints',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--embedding_path',\n",
    "    type=str,\n",
    "    default='glove/glove.6B.300d.txt',\n",
    "    help='GloVe embedding path',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--train_path',\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help='training dataset path',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--dev_path',\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help='dev dataset path',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--max_context_length',\n",
    "    type=int,\n",
    "    default=384,\n",
    "    help='maximum context length (do not change!)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--max_question_length',\n",
    "    type=int,\n",
    "    default=64,\n",
    "    help='maximum question length (do not change!)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--output_path',\n",
    "    type=str,\n",
    "    required=False,\n",
    "    help='predictions output path',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--shuffle_examples',\n",
    "    action='store_true',\n",
    "    help='shuffle training example at the beginning of each epoch',\n",
    ")\n",
    "\n",
    "# Optimization arguments.\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help='number of training epochs',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--batch_size',\n",
    "    type=int,\n",
    "    default=64,\n",
    "    help='training and evaluation batch size',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default=1e-3,\n",
    "    help='training learning rate',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight_decay',\n",
    "    type=float,\n",
    "    default=0.,\n",
    "    help='training weight decay',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--grad_clip',\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help='gradient norm clipping value',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--early_stop',\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help='number of epochs to wait until early stopping',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--do_train',\n",
    "    action='store_true',\n",
    "    help='flag to enable training',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--do_test',\n",
    "    action='store_true',\n",
    "    help='flag to enable testing',\n",
    ")\n",
    "\n",
    "# Model arguments.\n",
    "parser.add_argument(\n",
    "    '--vocab_size',\n",
    "    type=int,\n",
    "    default=50000,\n",
    "    help='vocabulary size (dynamically set, do not change!)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--embedding_dim',\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help='embedding dimension',\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--embedding_dim_spy',\n",
    "    type=int,\n",
    "    default=50,\n",
    "    help='embedding dimension for spy',\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--vocab_size_spy',\n",
    "    type=int,\n",
    "    default=50,\n",
    "    help='Spacy tag/dep num (dynamically set, do not change!)',\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--spy_type',\n",
    "    type=str,\n",
    "    default=\"dep\",\n",
    "    help='dep or tag',\n",
    ")\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    '--hidden_dim',\n",
    "    type=int,\n",
    "    default=256,\n",
    "    help='hidden state dimension',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--rnn_cell_type',\n",
    "    choices=['lstm', 'gru'],\n",
    "    default='lstm',\n",
    "    help='Type of RNN cell',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--bidirectional',\n",
    "    action='store_true',\n",
    "    help='use bidirectional RNN',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--dropout',\n",
    "    type=float,\n",
    "    default=0.,\n",
    "    help='dropout on passage and question vectors',\n",
    ")\n",
    "\n",
    "\n",
    "def _print_arguments(args):\n",
    "    \"\"\"Pretty prints command line args to stdout.\n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "    \"\"\"\n",
    "\n",
    "    args_dict = vars(args)\n",
    "    pprint.pprint(args_dict)\n",
    "\n",
    "\n",
    "def _select_model(args):\n",
    "    \"\"\"\n",
    "    Selects and initializes model. To integrate custom models, (1)\n",
    "    add the model name to the parser choices above, and (2) modify\n",
    "    the conditional statements to include an instance of the model.\n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "\n",
    "    Returns:\n",
    "        Instance of a PyTorch model supplied with args.\n",
    "    \"\"\"\n",
    "    if args.model == 'baseline':\n",
    "        return BaselineReader(args)\n",
    "    else:\n",
    "        raise RuntimeError(f'model \\'{args.model}\\' not recognized!')\n",
    "\n",
    "\n",
    "def _early_stop(args, eval_history):\n",
    "    \"\"\"\n",
    "    Determines early stopping conditions. If the evaluation loss has\n",
    "    not improved after `args.early_stop` epoch(s), then training\n",
    "    is ended prematurely. \n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "        eval_history: List of booleans that indicate whether an epoch resulted\n",
    "            in a model checkpoint, or in other words, if the evaluation loss\n",
    "            was lower than previous losses.\n",
    "\n",
    "    Returns:\n",
    "        Boolean indicating whether training should stop.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        len(eval_history) > args.early_stop\n",
    "        and not any(eval_history[-args.early_stop:])\n",
    "    )\n",
    "\n",
    "\n",
    "def _calculate_loss(\n",
    "    start_logits, end_logits, start_positions, end_positions\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates cross-entropy loss for QA samples, which is defined as\n",
    "    the mean of the loss values incurred by the starting and ending position\n",
    "    distributions when compared to the gold endpoints.\n",
    "\n",
    "    Args:\n",
    "        start_logits: Predicted distribution over start positions.\n",
    "        end_logits: Predicted distribution over end positions.\n",
    "        start_positions: Gold start positions.\n",
    "        end_positions: Gold end positions.\n",
    "\n",
    "    Returns:\n",
    "        Loss value for a batch of sasmples.\n",
    "    \"\"\"\n",
    "    # If the gold span is outside the scope of the maximum\n",
    "    # context length, then ignore these indices when computing the loss.\n",
    "    ignored_index = start_logits.size(1)\n",
    "    start_positions.clamp_(0, ignored_index)\n",
    "    end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "    # Compute the cross-entropy loss for the start and end logits.\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "    start_loss = criterion(start_logits, start_positions)\n",
    "    end_loss = criterion(end_logits, end_positions)\n",
    "\n",
    "    return (start_loss + end_loss) / 2.\n",
    "\n",
    "\n",
    "def train(args, epoch, model, dataset):\n",
    "    \"\"\"\n",
    "    Trains the model for a single epoch using the training dataset.\n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "        epoch: Epoch number (used in the `tqdm` bar).\n",
    "        model: Instance of the PyTorch model.\n",
    "        dataset: Training dataset.\n",
    "\n",
    "    Returns:\n",
    "        Training cross-entropy loss normalized across all samples.\n",
    "    \"\"\"\n",
    "    # Set the model in \"train\" mode.\n",
    "    model.train()\n",
    "\n",
    "    # Cumulative loss and steps.\n",
    "    train_loss = 0.\n",
    "    train_steps = 0\n",
    "\n",
    "    # Set up optimizer.\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=args.learning_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "\n",
    "    # Set up training dataloader. Creates `args.batch_size`-sized\n",
    "    # batches from available samples.\n",
    "    train_dataloader = tqdm(\n",
    "        dataset.get_batch(shuffle_examples=args.shuffle_examples),\n",
    "        **_TQDM_OPTIONS,\n",
    "    )\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        # Zero gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward inputs, calculate loss, optimize model.\n",
    "        start_logits, end_logits = model(batch)\n",
    "        loss = _calculate_loss(\n",
    "            start_logits,\n",
    "            end_logits,\n",
    "            batch['start_positions'],\n",
    "            batch['end_positions'],\n",
    "        )\n",
    "        loss.backward()\n",
    "        if args.grad_clip > 0.:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm bar.\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        train_dataloader.set_description(\n",
    "            f'[train] epoch = {epoch}, loss = {train_loss / train_steps:.6f}'\n",
    "        )\n",
    "\n",
    "    return train_loss / train_steps\n",
    "\n",
    "\n",
    "def evaluate(args, epoch, model, dataset):\n",
    "    \"\"\"\n",
    "    Evaluates the model for a single epoch using the development dataset.\n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "        epoch: Epoch number (used in the `tqdm` bar).\n",
    "        model: Instance of the PyTorch model.\n",
    "        dataset: Development dataset.\n",
    "\n",
    "    Returns:\n",
    "        Evaluation cross-entropy loss normalized across all samples.\n",
    "    \"\"\"\n",
    "    # Set the model in \"evaluation\" mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Cumulative loss and steps.\n",
    "    eval_loss = 0.\n",
    "    eval_steps = 0\n",
    "\n",
    "    # Set up evaluation dataloader. Creates `args.batch_size`-sized\n",
    "    # batches from available samples. Does not shuffle.\n",
    "    eval_dataloader = tqdm(\n",
    "        dataset.get_batch(shuffle_examples=False),\n",
    "        **_TQDM_OPTIONS,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            # Forward inputs, calculate loss.\n",
    "            start_logits, end_logits = model(batch)\n",
    "            loss = _calculate_loss(\n",
    "                start_logits,\n",
    "                end_logits,\n",
    "                batch['start_positions'],\n",
    "                batch['end_positions'],\n",
    "            )\n",
    "\n",
    "            # Update tqdm bar.\n",
    "            eval_loss += loss.item()\n",
    "            eval_steps += 1\n",
    "            eval_dataloader.set_description(\n",
    "                f'[eval] epoch = {epoch}, loss = {eval_loss / eval_steps:.6f}'\n",
    "            )\n",
    "\n",
    "    return eval_loss / eval_steps\n",
    "\n",
    "\n",
    "def write_predictions(args, model, dataset):\n",
    "    \"\"\"\n",
    "    Writes model predictions to an output file. The official QA metrics (EM/F1)\n",
    "    can be computed using `evaluation.py`. \n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "        model: Instance of the PyTorch model.\n",
    "        dataset: Test dataset (technically, the development dataset since the\n",
    "            official test datasets are blind and hosted by official servers).\n",
    "    \"\"\"\n",
    "    # Load model checkpoint.\n",
    "    model.load_state_dict(torch.load(args.model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    # Set up test dataloader.\n",
    "    test_dataloader = tqdm(\n",
    "        dataset.get_batch(shuffle_examples=False),\n",
    "        **_TQDM_OPTIONS,\n",
    "    )\n",
    "\n",
    "    # Output predictions.\n",
    "    outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (i, batch) in enumerate(test_dataloader):\n",
    "            # Forward inputs.\n",
    "            start_logits, end_logits = model(batch)\n",
    "\n",
    "            # Form distributions over start and end positions.\n",
    "            batch_start_probs = F.softmax(start_logits, 1)\n",
    "            batch_end_probs = F.softmax(end_logits, 1)\n",
    "\n",
    "            for j in range(start_logits.size(0)):\n",
    "                # Find question index and passage.\n",
    "                sample_index = args.batch_size * i + j\n",
    "                qid, passage, _, _, _ = dataset.samples[sample_index]\n",
    "\n",
    "                # Unpack start and end probabilities. Find the constrained\n",
    "                # (start, end) pair that has the highest joint probability.\n",
    "                start_probs = unpack(batch_start_probs[j])\n",
    "                end_probs = unpack(batch_end_probs[j])\n",
    "                start_index, end_index = search_span_endpoints(\n",
    "                        start_probs, end_probs\n",
    "                )\n",
    "                \n",
    "                # Grab predicted span.\n",
    "                pred_span = ' '.join(passage[start_index:(end_index + 1)])\n",
    "\n",
    "                # Add prediction to outputs.\n",
    "                outputs.append({'qid': qid, 'answer': pred_span})\n",
    "\n",
    "    # Write predictions to output file.\n",
    "    with open(args.output_path, 'w+') as f:\n",
    "        for elem in outputs:\n",
    "            f.write(f'{json.dumps(elem)}\\n')\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Main function for training, evaluating, and checkpointing.\n",
    "\n",
    "    Args:\n",
    "        args: `argparse` object.\n",
    "    \"\"\"\n",
    "    # Print arguments.\n",
    "    print('\\nusing arguments:')\n",
    "    _print_arguments(args)\n",
    "    print()\n",
    "\n",
    "    # Check if GPU is available.\n",
    "    if not args.use_gpu and torch.cuda.is_available():\n",
    "        print('warning: GPU is available but args.use_gpu = False')\n",
    "        print()\n",
    "\n",
    "    # Set up datasets.\n",
    "    train_dataset = QADataset(args, args.train_path)\n",
    "    dev_dataset = QADataset(args, args.dev_path)\n",
    "\n",
    "    # Create vocabulary and tokenizer.\n",
    "    vocabulary = Vocabulary(train_dataset.samples, args.vocab_size)\n",
    "    tokenizer = Tokenizer(vocabulary)\n",
    "    for dataset in (train_dataset, dev_dataset):\n",
    "        dataset.register_tokenizer(tokenizer)\n",
    "    args.vocab_size = len(vocabulary)\n",
    "    args.pad_token_id = tokenizer.pad_token_id\n",
    "    print(f'vocab words = {len(vocabulary)}')\n",
    "\n",
    "    # Print number of samples.\n",
    "    print(f'train samples = {len(train_dataset)}')\n",
    "    print(f'dev samples = {len(dev_dataset)}')\n",
    "    print()\n",
    "\n",
    "    # set up vocab_size_spy based on spy_type \n",
    "    if args.spy_type == \"tag\":\n",
    "       args.vocab_size_spy =  len(vocabulary.tag_list)\n",
    "    elif args.spy_type == \"dep\":\n",
    "        args.vocab_size_spy =  len(vocabulary.dep_list)\n",
    "\n",
    "    # Select model.\n",
    "    model = _select_model(args)\n",
    "    num_pretrained = model.load_pretrained_embeddings(\n",
    "        vocabulary, args.embedding_path\n",
    "    )\n",
    "    pct_pretrained = round(num_pretrained / len(vocabulary) * 100., 2)\n",
    "    print(f'using pre-trained embeddings from \\'{args.embedding_path}\\'')\n",
    "    print(\n",
    "        f'initialized {num_pretrained}/{len(vocabulary)} '\n",
    "        f'embeddings ({pct_pretrained}%)'\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    if args.use_gpu:\n",
    "        model = cuda(args, model)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'using model \\'{args.model}\\' ({params} params)')\n",
    "    print(model)\n",
    "    print()\n",
    "\n",
    "    if args.do_train:\n",
    "        # Track training statistics for checkpointing.\n",
    "        eval_history = []\n",
    "        best_eval_loss = float('inf')\n",
    "\n",
    "        # Begin training.\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            # Perform training and evaluation steps.\n",
    "            train_loss = train(args, epoch, model, train_dataset)\n",
    "            eval_loss = evaluate(args, epoch, model, dev_dataset)\n",
    "\n",
    "            # If the model's evaluation loss yields a global improvement,\n",
    "            # checkpoint the model.\n",
    "            eval_history.append(eval_loss < best_eval_loss)\n",
    "            if eval_loss < best_eval_loss:\n",
    "                best_eval_loss = eval_loss\n",
    "                torch.save(model.state_dict(), args.model_path)\n",
    "            \n",
    "            print(\n",
    "                f'epoch = {epoch} | '\n",
    "                f'train loss = {train_loss:.6f} | '\n",
    "                f'eval loss = {eval_loss:.6f} | '\n",
    "                f\"{'saving model!' if eval_history[-1] else ''}\"\n",
    "            )\n",
    "\n",
    "            # If early stopping conditions are met, stop training.\n",
    "            if _early_stop(args, eval_history):\n",
    "                suffix = 's' if args.early_stop > 1 else ''\n",
    "                print(\n",
    "                    f'no improvement after {args.early_stop} epoch{suffix}. '\n",
    "                    'early stopping...'\n",
    "                )\n",
    "                print()\n",
    "                break\n",
    "\n",
    "    if args.do_test:\n",
    "        # Write predictions to the output file. Use the printed command\n",
    "        # below to obtain official EM/F1 metrics.\n",
    "        write_predictions(args, model, dev_dataset)\n",
    "        eval_cmd = (\n",
    "            'python3 evaluate.py '\n",
    "            f'--dataset_path {args.dev_path} '\n",
    "            f'--output_path {args.output_path}'\n",
    "        )\n",
    "        print()\n",
    "        print(f'predictions written to \\'{args.output_path}\\'')\n",
    "        print(f'compute EM/F1 with: \\'{eval_cmd}\\'')\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse_args() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16d1a339d2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        \u001b[0mbidirectional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        \u001b[0mdo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                        \u001b[0mdo_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                       ))\n",
      "\u001b[0;31mTypeError\u001b[0m: parse_args() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "main(parser.parse_args(model = \"baseline\", \n",
    "                       model_path = \"squad_model.pt\",\n",
    "                       train_path = \"datasets/squad_train.jsonl.gz\",\n",
    "                       dev_path = \"datasets/squad_dev.jsonl.gz\",\n",
    "                       hidden_dim = 256,\n",
    "                       bidirectional = True,\n",
    "                       do_train = True,\n",
    "                       do_test = True\n",
    "                      ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
